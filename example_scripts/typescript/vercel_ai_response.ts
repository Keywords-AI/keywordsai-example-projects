import { KeywordsAIExporter } from "../src/index.js";
import { BasicTracerProvider, SimpleSpanProcessor } from "@opentelemetry/sdk-trace-base";
import { trace, context } from "@opentelemetry/api";
import { AsyncHooksContextManager } from "@opentelemetry/context-async-hooks";
import { generateText, streamText } from "ai";
// å‡è®¾ä½ å·²ç»åœ¨é¡¹ç›®ä¸­æ‰©å±•äº† openai å¯¹è±¡æˆ–è€…è¿™æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰å®žä¾‹
// å¦‚æžœæ˜¯æ ‡å‡† SDKï¼Œè¿™é‡Œå¯èƒ½éœ€è¦ cast: (openai as any).responses
import { openai } from "@ai-sdk/openai"; 
import { config } from "dotenv";
import path from "path";
import { fileURLToPath } from "url";

// ============================================================================
// 1. åˆå§‹åŒ– Context Manager (å¼‚æ­¥è¿½è¸ªæ ¸å¿ƒ)
// ============================================================================
const contextManager = new AsyncHooksContextManager();
contextManager.enable();
context.setGlobalContextManager(contextManager);

// ============================================================================
// 2. é…ç½® Exporter
// ============================================================================
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
config({ path: path.resolve(__dirname, "../.env") });

const exporter = new KeywordsAIExporter({
  apiKey: process.env.KEYWORDSAI_API_KEY,
  debug: true, // è°ƒè¯•æ¨¡å¼ï¼Œä¾¿äºŽè§‚å¯Ÿå‘é€æƒ…å†µ
});

const provider = new BasicTracerProvider();
provider.addSpanProcessor(new SimpleSpanProcessor(exporter));
provider.register();

// ============================================================================
// 3. Response API ä¸“ç”¨ç¤ºä¾‹ (Tests 3-6)
// ============================================================================
async function main() {
  console.log("ðŸš€ Starting Keywords AI [Response API] Example...");
  const tracer = trace.getTracer("keywords-ai-response-example");

  await tracer.startActiveSpan("response-api-demo", async (rootSpan) => {
    try {
      
      // ---------------------------------------------------------
      // åœºæ™¯ 1: å•æ¬¡æ–‡æœ¬ç”Ÿæˆ (Standard Response)
      // å¯¹åº”ä½ çš„ [TEST 3]
      // ---------------------------------------------------------
      console.log("\n1ï¸âƒ£  Testing Standard Response (generateText)...");
      
      const result = await generateText({
        // æ ¸å¿ƒï¼šä½¿ç”¨ .responses å˜ä½“æ¥è§¦å‘ Exporter çš„è‡ªåŠ¨è¯†åˆ«é€»è¾‘
        // @ts-ignore (å¿½ç•¥ TS æ£€æŸ¥ï¼Œå¦‚æžœä½ çš„ openai ç±»åž‹æ²¡æ›´æ–°)
        model: openai.responses('gpt-4o'), 
        prompt: "Give me a 5-word fun fact about space.",
        experimental_telemetry: {
          isEnabled: true,
          functionId: "test-3-response",
          metadata: {
            userId: "user-new-test-999",
            customer_email: "user@example.com",
            customer_name: "John Doe",
            conversationId: "conv-abc-123",
            // â­ï¸ æœ€ä½³å®žè·µï¼šæ˜¾å¼æ ‡è®°ï¼Œç¡®ä¿ 100% è¯†åˆ«ä¸º Response
            custom_log_type: "response" 
          }
        }
      });
      console.log(`âœ… Output: ${result.text}`);


      // ---------------------------------------------------------
      // åœºæ™¯ 2: æµå¼å“åº” (Streaming Response)
      // å¯¹åº”ä½ çš„ [TEST 4/5] - å³ä½¿æ˜¯æµï¼Œä¹Ÿæ˜¯ Response ä¸šåŠ¡
      // ---------------------------------------------------------
      console.log("\n2ï¸âƒ£  Testing Streaming Response (streamText)...");
      
      const streamResult = await streamText({
        // @ts-ignore
        model: openai.responses('gpt-4o-mini'),
        prompt: "Count from 1 to 5.",
        experimental_telemetry: {
          isEnabled: true,
          functionId: "test-4-stream-response",
          metadata: {
            userId: "user-new-test-999",
            // â­ï¸ å…³é”®ï¼šå³ä¾¿æ˜¯æµï¼Œå› ä¸ºä¸šåŠ¡å±žæ€§æ˜¯ Function Responseï¼Œæ‰€ä»¥æ ‡è®°ä¸º response
            custom_log_type: "response" 
          }
        }
      });

      process.stdout.write("âœ… Stream Output: ");
      for await (const chunk of streamResult.textStream) {
        process.stdout.write(chunk);
      }
      console.log("\n");


      // ---------------------------------------------------------
      // åœºæ™¯ 3: ç»“æž„åŒ– JSON ç”Ÿæˆ (Structured Object)
      // å¯¹åº”ä½ çš„ [TEST 6] - è¿™ç§æœ€åº”è¯¥è¢«å½’ç±»ä¸º Response
      // ---------------------------------------------------------
      console.log("\n3ï¸âƒ£  Testing JSON/Structured Response...");
      
      // æ³¨æ„ï¼šè¿™é‡Œä¹Ÿå¯ä»¥ç”¨ generateObjectï¼Œä½†å¦‚æžœç”¨ generateText + json modeï¼š
      const jsonResult = await generateText({
        // @ts-ignore
        model: openai.responses('gpt-4o-mini'),
        prompt: "Generate a JSON object with a 'color' and 'hex' field for red.",
        // å¼ºåˆ¶ JSON æ¨¡å¼ï¼ŒExporter ä¼šè‡ªåŠ¨è¯†åˆ« gen_ai.usage.type
        // @ts-ignore
        mode: 'json', 
        experimental_telemetry: {
          isEnabled: true,
          functionId: "test-6-json-response",
          metadata: {
            userId: "user-new-test-999",
            custom_log_type: "response"
          }
        }
      });
      console.log(`âœ… JSON Output: ${jsonResult.text}`);

    } catch (error) {
      console.error("âŒ Error:", error);
      rootSpan.recordException(error as Error);
    } finally {
      rootSpan.end();
    }
  });

  console.log("\nâ³ Waiting for spans to be exported...");
  await new Promise((resolve) => setTimeout(resolve, 2000));
}

main().catch(console.error);
