{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Workflow Verification - Self-Contained\n",
        "\n",
        "This notebook demonstrates and verifies the complete workflow as documented in `experiment_v2_workflow_implementation.md`.\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ      CUSTOM WORKFLOW - USER FLOW            ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "                START\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  1. Create Experiment       ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  2. Get Placeholder Traces  ‚îÇ\n",
        "    ‚îÇ     (with inputs)           ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  3. Process with Your Code  ‚îÇ\n",
        "    ‚îÇ     (external)              ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  4. Submit Results          ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  5. View Final Results      ‚îÇ\n",
        "    ‚îÇ     (with scores)           ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                  ‚Üì\n",
        "                 END\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set your API key and base URL here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "# API Configuration\n",
        "BASE_URL = os.getenv(\"KEYWORDSAI_BASE_URL\")\n",
        "API_KEY = os.getenv(\"KEYWORDSAI_API_KEY\")  # Replace with your actual API key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and All Functions\n",
        "\n",
        "All necessary imports and function definitions in one place.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "from typing import Dict, Any, List, Optional\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ============================================================================\n",
        "# CONSISTENT NAMING FOR ALL COMPONENTS - MAKES CLEANUP EASY!\n",
        "# ============================================================================\n",
        "WORKFLOW_NAME = \"Custom workflow test\"\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def print_step(step_number: int, title: str):\n",
        "    \"\"\"Print a formatted step header.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"STEP {step_number}: {title}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "def print_success(message: str):\n",
        "    \"\"\"Print a success message.\"\"\"\n",
        "    print(f\"‚úÖ {message}\")\n",
        "\n",
        "def print_warning(message: str):\n",
        "    \"\"\"Print a warning message.\"\"\"\n",
        "    print(f\"‚ö†Ô∏è  {message}\")\n",
        "\n",
        "def print_error(message: str):\n",
        "    \"\"\"Print an error message.\"\"\"\n",
        "    print(f\"‚ùå {message}\")\n",
        "\n",
        "def print_info(message: str):\n",
        "    \"\"\"Print an info message.\"\"\"\n",
        "    print(f\"‚ÑπÔ∏è  {message}\")\n",
        "\n",
        "def wait_for_processing(seconds: int = 15):\n",
        "    \"\"\"Wait for async processing to complete.\"\"\"\n",
        "    print(f\"\\nWaiting {seconds} seconds for processing...\")\n",
        "    time.sleep(seconds)\n",
        "    print(\"‚úì Wait complete\")\n",
        "\n",
        "# ============================================================================\n",
        "# API FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def create_log(\n",
        "    model: str,\n",
        "    input_messages: List[Dict[str, str]],\n",
        "    output_message: Dict[str, str],\n",
        "    custom_identifier: Optional[str] = None,\n",
        "    span_name: Optional[str] = None,\n",
        "    **kwargs\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Create a new log entry in Keywords AI.\"\"\"\n",
        "    url = f\"{BASE_URL}/request-logs/create\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"input\": input_messages,\n",
        "        \"output\": output_message\n",
        "    }\n",
        "    \n",
        "    if custom_identifier:\n",
        "        payload[\"custom_identifier\"] = custom_identifier\n",
        "    if span_name:\n",
        "        payload[\"span_name\"] = span_name\n",
        "    \n",
        "    payload.update(kwargs)\n",
        "    \n",
        "    print(\"Creating log entry...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Model: {model}\")\n",
        "    print(f\"  Input messages: {len(input_messages)}\")\n",
        "    if custom_identifier:\n",
        "        print(f\"  Custom identifier: {custom_identifier}\")\n",
        "    if span_name:\n",
        "        print(f\"  Span name: {span_name}\")\n",
        "    print(f\"  Request Body: {json.dumps(payload, indent=2)}\")\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"\\n‚úì Log created successfully\")\n",
        "    if 'unique_id' in data:\n",
        "        print(f\"  Log ID (unique_id): {data.get('unique_id')}\")\n",
        "    if 'id' in data:\n",
        "        print(f\"  Log ID: {data.get('id')}\")\n",
        "    if 'trace_id' in data:\n",
        "        print(f\"  Trace ID: {data.get('trace_id')}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def create_dataset(\n",
        "    name: str, \n",
        "    description: str = \"\", \n",
        "    dataset_type: str = \"sampling\",\n",
        "    sampling: int = 50,\n",
        "    start_time: Optional[str] = None,\n",
        "    end_time: Optional[str] = None,\n",
        "    initial_log_filters: Optional[Dict[str, Any]] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Create a new dataset from logs with sampling and filtering.\"\"\"\n",
        "    url = f\"{BASE_URL}/datasets\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"type\": dataset_type\n",
        "    }\n",
        "    \n",
        "    if sampling and not initial_log_filters:\n",
        "        payload[\"sampling\"] = sampling\n",
        "    \n",
        "    if start_time:\n",
        "        payload[\"start_time\"] = start_time\n",
        "    if end_time:\n",
        "        payload[\"end_time\"] = end_time\n",
        "        \n",
        "    if initial_log_filters:\n",
        "        payload[\"initial_log_filters\"] = initial_log_filters\n",
        "    \n",
        "    print(\"Creating dataset...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Name: {name}\")\n",
        "    print(f\"  Type: {dataset_type}\")\n",
        "    print(f\"  Request Body: {json.dumps(payload, indent=2)}\")\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"\\n‚úì Dataset created successfully\")\n",
        "    print(f\"  Dataset ID: {data.get('id')}\")\n",
        "    print(f\"  Name: {data.get('name')}\")\n",
        "    print(f\"  Status: {data.get('status', 'N/A')}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def list_dataset_logs(dataset_id: str, page: int = 1, page_size: int = 100) -> Dict[str, Any]:\n",
        "    \"\"\"List logs from a specific dataset.\"\"\"\n",
        "    url = f\"{BASE_URL}/datasets/{dataset_id}/logs/list\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    params = {\n",
        "        \"page\": page,\n",
        "        \"page_size\": page_size\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nListing logs for dataset {dataset_id}...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Method: GET\")\n",
        "    print(f\"  Params: {params}\")\n",
        "    \n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    results = data.get('results', [])\n",
        "    total_count = data.get('count', 0)\n",
        "    \n",
        "    print(f\"‚úì Retrieved {len(results)} logs (page {page})\")\n",
        "    print(f\"  Total logs in dataset: {total_count}\")\n",
        "    \n",
        "    if results:\n",
        "        print(f\"\\n  üìã First log structure:\")\n",
        "        first_log = results[0]\n",
        "        print(f\"    Keys: {list(first_log.keys())}\")\n",
        "        if 'id' in first_log:\n",
        "            print(f\"    Log ID: {first_log.get('id')}\")\n",
        "        if 'input' in first_log:\n",
        "            input_preview = str(first_log.get('input'))[:100]\n",
        "            print(f\"    Input preview: {input_preview}...\")\n",
        "        if 'output' in first_log:\n",
        "            output_preview = str(first_log.get('output'))[:100]\n",
        "            print(f\"    Output preview: {output_preview}...\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def create_evaluator(\n",
        "    name: str,\n",
        "    evaluator_slug: str,\n",
        "    evaluator_type: str,\n",
        "    score_value_type: str,\n",
        "    description: str = \"\",\n",
        "    configurations: Optional[Dict[str, Any]] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Create a custom evaluator in Keywords AI.\"\"\"\n",
        "    url = f\"{BASE_URL}/evaluators\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"name\": name,\n",
        "        \"evaluator_slug\": evaluator_slug,\n",
        "        \"type\": evaluator_type,\n",
        "        \"score_value_type\": score_value_type,\n",
        "        \"description\": description\n",
        "    }\n",
        "    \n",
        "    if configurations:\n",
        "        payload[\"configurations\"] = configurations\n",
        "    \n",
        "    print(\"Creating evaluator...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Name: {name}\")\n",
        "    print(f\"  Slug: {evaluator_slug}\")\n",
        "    print(f\"  Type: {evaluator_type}\")\n",
        "    print(f\"  Score Type: {score_value_type}\")\n",
        "    print(f\"  Request Body: {json.dumps(payload, indent=2)}\")\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"\\n‚úì Evaluator created successfully\")\n",
        "    if 'id' in data:\n",
        "        print(f\"  Evaluator ID: {data.get('id')}\")\n",
        "    if 'evaluator_slug' in data:\n",
        "        print(f\"  Evaluator Slug: {data.get('evaluator_slug')}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def create_experiment(name: str, description: str, dataset_id: str, \n",
        "                     workflows: List[Dict], evaluator_slugs: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"Create a new custom workflow experiment.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"dataset_id\": dataset_id,\n",
        "        \"workflows\": workflows,\n",
        "        \"evaluator_slugs\": evaluator_slugs\n",
        "    }\n",
        "    \n",
        "    print(\"Creating custom workflow experiment...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Name: {name}\")\n",
        "    print(f\"  Dataset: {dataset_id}\")\n",
        "    print(f\"  Evaluators: {', '.join(evaluator_slugs)}\")\n",
        "    print(f\"  Request Body: {json.dumps(payload, indent=2)}\")\n",
        "    \n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"\\n‚úì Experiment created with ID: {data.get('id')}\")\n",
        "    print(f\"  Status: {data.get('status')}\")\n",
        "    print(\"  Placeholder traces are being created asynchronously...\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def list_experiment_logs(exp_id: str, filters: Optional[Dict[str, Any]] = None, \n",
        "                        page: int = 1, page_size: int = 100) -> Dict[str, Any]:\n",
        "    \"\"\"List traces for an experiment with optional filtering.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/{exp_id}/logs/list/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    params = {\n",
        "        \"page\": page,\n",
        "        \"page_size\": page_size\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nListing experiment logs for {exp_id}...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    print(f\"  Params: {params}\")\n",
        "    if filters:\n",
        "        print(f\"  Filters: {json.dumps(filters, indent=2)}\")\n",
        "    \n",
        "    try:\n",
        "        if filters:\n",
        "            request_body = {\"filters\": filters}\n",
        "            print(f\"  Method: POST\")\n",
        "            print(f\"  Request Body: {json.dumps(request_body, indent=2)}\")\n",
        "            response = requests.post(url, headers=headers, json=request_body, params=params)\n",
        "        else:\n",
        "            print(f\"  Method: GET\")\n",
        "            response = requests.get(url, headers=headers, params=params)\n",
        "        \n",
        "        response.raise_for_status()\n",
        "        \n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"‚ùå Error listing logs: {e}\")\n",
        "        print(f\"   Status code: {e.response.status_code}\")\n",
        "        \n",
        "        try:\n",
        "            error_json = e.response.json()\n",
        "            print(f\"   Response: {error_json}\")\n",
        "        except:\n",
        "            print(f\"   Response (text): {e.response.text[:500]}\")\n",
        "        \n",
        "        if filters and e.response.status_code == 500:\n",
        "            print(\"\\n‚ö† Retrying without filters...\")\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, params=params)\n",
        "                response.raise_for_status()\n",
        "                print(\"‚úì GET without filters succeeded\")\n",
        "            except Exception as retry_error:\n",
        "                print(f\"‚ùå Retry also failed: {retry_error}\")\n",
        "                raise e\n",
        "        else:\n",
        "            raise\n",
        "    \n",
        "    data = response.json()\n",
        "    results = data.get('results', [])\n",
        "    print(f\"‚úì Found {len(results)} logs (page {page})\")\n",
        "    print(f\"  Total count: {data.get('count', 0)}\")\n",
        "    \n",
        "    if results:\n",
        "        status_counts = {}\n",
        "        for log in results:\n",
        "            status = log.get('status', 'unknown')\n",
        "            status_counts[status] = status_counts.get(status, 0) + 1\n",
        "        print(f\"  Status breakdown: {status_counts}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def get_trace_details(exp_id: str, trace_id: str, include_full_span_tree: bool = True) -> Dict[str, Any]:\n",
        "    \"\"\"Get detailed information about a specific trace.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/{exp_id}/logs/{trace_id}/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
        "    }\n",
        "    \n",
        "    params = {}\n",
        "    if include_full_span_tree:\n",
        "        params[\"detail\"] = 1\n",
        "    \n",
        "    print(f\"  Getting trace details...\")\n",
        "    print(f\"    URL: {url}\")\n",
        "    print(f\"    Method: GET\")\n",
        "    if params:\n",
        "        print(f\"    Params: {params}\")\n",
        "    \n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    return response.json()\n",
        "\n",
        "def submit_workflow_results(exp_id: str, trace_id: str, \n",
        "                           input_data: Any, output_data: Any,\n",
        "                           name: Optional[str] = None, \n",
        "                           metadata: Optional[Dict] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Update a placeholder trace with your custom workflow results.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/{exp_id}/logs/{trace_id}/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"input\": input_data,\n",
        "        \"output\": output_data\n",
        "    }\n",
        "    \n",
        "    if name:\n",
        "        payload[\"name\"] = name\n",
        "    if metadata:\n",
        "        payload[\"metadata\"] = metadata\n",
        "    \n",
        "    print(f\"    Submitting results to: {url}\")\n",
        "    print(f\"    Method: PATCH\")\n",
        "    print(f\"    Payload keys: {list(payload.keys())}\")\n",
        "    print(f\"    Input type: {type(input_data).__name__}\")\n",
        "    print(f\"    Output type: {type(output_data).__name__}\")\n",
        "    \n",
        "    response = requests.patch(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    updated_trace = response.json()\n",
        "    \n",
        "    print(f\"    Response status: {response.status_code}\")\n",
        "    \n",
        "    response_status = updated_trace.get('status')\n",
        "    if response_status:\n",
        "        print(f\"    Trace status: {response_status}\")\n",
        "    \n",
        "    return updated_trace\n",
        "\n",
        "def get_experiment_summary(exp_id: str, filters: Optional[List[Dict]] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Get aggregated summary statistics for experiment traces.\"\"\"\n",
        "    url = f\"{BASE_URL}/v2/experiments/{exp_id}/logs/summary/\"\n",
        "    \n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nGetting experiment summary for {exp_id}...\")\n",
        "    print(f\"  URL: {url}\")\n",
        "    \n",
        "    if filters:\n",
        "        request_body = {\"filters\": filters}\n",
        "        print(f\"  Method: POST\")\n",
        "        print(f\"  Request Body: {json.dumps(request_body, indent=2)}\")\n",
        "        response = requests.post(url, headers=headers, json=request_body)\n",
        "    else:\n",
        "        print(f\"  Method: GET\")\n",
        "        response = requests.get(url, headers=headers)\n",
        "    \n",
        "    response.raise_for_status()\n",
        "    \n",
        "    data = response.json()\n",
        "    print(f\"‚úì Summary retrieved:\")\n",
        "    print(f\"  Total traces: {data.get('total_count', 0)}\")\n",
        "    print(f\"  Total cost: ${data.get('total_cost', 0):.4f}\")\n",
        "    print(f\"  Total tokens: {data.get('total_tokens', 0)}\")\n",
        "    print(f\"  Avg latency: {data.get('avg_latency', 0):.2f}s\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "def process_with_custom_logic(input_data: Any) -> Dict[str, Any]:\n",
        "    \"\"\"Your custom workflow processing logic.\"\"\"\n",
        "    try:\n",
        "        if isinstance(input_data, str):\n",
        "            try:\n",
        "                parsed_input = json.loads(input_data)\n",
        "            except:\n",
        "                parsed_input = input_data\n",
        "        else:\n",
        "            parsed_input = input_data\n",
        "        \n",
        "        result = {\n",
        "            \"status\": \"processed\",\n",
        "            \"message\": f\"Successfully processed input with {len(str(parsed_input))} characters\",\n",
        "            \"input_preview\": str(parsed_input)[:100],\n",
        "            \"custom_field\": \"your_custom_value\"\n",
        "        }\n",
        "        \n",
        "        return {\n",
        "            \"output\": result,\n",
        "            \"metadata\": {\n",
        "                \"processing_timestamp\": time.time(),\n",
        "                \"processor\": \"custom_workflow_v1\"\n",
        "            }\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"output\": {\n",
        "                \"status\": \"error\",\n",
        "                \"error_message\": str(e)\n",
        "            },\n",
        "            \"metadata\": {\n",
        "                \"processing_timestamp\": time.time(),\n",
        "                \"processor\": \"custom_workflow_v1\",\n",
        "                \"error\": True\n",
        "            }\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Variables\n",
        "\n",
        "These variables will track resources created throughout the workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Track resources created\n",
        "log_ids = []\n",
        "dataset_id = None\n",
        "evaluator_slug = None\n",
        "experiment_id = None\n",
        "trace_ids = []\n",
        "dataset_log_count = 0\n",
        "trace_count = 0\n",
        "processed_count = 0\n",
        "traces_with_evaluators = 0\n",
        "final_status_breakdown = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create Sample Logs\n",
        "\n",
        "Create 3 sample logs that will be added to the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 1: Create Sample Logs\n",
            "======================================================================\n",
            "\n",
            "Creating log 1/3...\n",
            "Creating log entry...\n",
            "  URL: https://api.keywordsai.co/api/request-logs/create\n",
            "  Model: gpt-4\n",
            "  Input messages: 2\n",
            "  Custom identifier: Custom workflow test_log_1\n",
            "  Span name: Custom workflow test\n",
            "  Request Body: {\n",
            "  \"model\": \"gpt-4\",\n",
            "  \"input\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"You are a helpful assistant.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"What is machine learning?\"\n",
            "    }\n",
            "  ],\n",
            "  \"output\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience.\"\n",
            "  },\n",
            "  \"custom_identifier\": \"Custom workflow test_log_1\",\n",
            "  \"span_name\": \"Custom workflow test\"\n",
            "}\n",
            "\n",
            "‚úì Log created successfully\n",
            "  Log ID (unique_id): 07f3059ef0564f5095dc7425166cd20a\n",
            "‚úÖ Log created with ID: 07f3059ef0564f50...\n",
            "\n",
            "Creating log 2/3...\n",
            "Creating log entry...\n",
            "  URL: https://api.keywordsai.co/api/request-logs/create\n",
            "  Model: gpt-4\n",
            "  Input messages: 2\n",
            "  Custom identifier: Custom workflow test_log_2\n",
            "  Span name: Custom workflow test\n",
            "  Request Body: {\n",
            "  \"model\": \"gpt-4\",\n",
            "  \"input\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"You are a helpful assistant.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"Explain neural networks briefly.\"\n",
            "    }\n",
            "  ],\n",
            "  \"output\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"Neural networks are computing systems inspired by biological neural networks in animal brains.\"\n",
            "  },\n",
            "  \"custom_identifier\": \"Custom workflow test_log_2\",\n",
            "  \"span_name\": \"Custom workflow test\"\n",
            "}\n",
            "\n",
            "‚úì Log created successfully\n",
            "  Log ID (unique_id): e8384e0bf1c847be89efed6eb0286e44\n",
            "‚úÖ Log created with ID: e8384e0bf1c847be...\n",
            "\n",
            "Creating log 3/3...\n",
            "Creating log entry...\n",
            "  URL: https://api.keywordsai.co/api/request-logs/create\n",
            "  Model: gpt-4\n",
            "  Input messages: 2\n",
            "  Custom identifier: Custom workflow test_log_3\n",
            "  Span name: Custom workflow test\n",
            "  Request Body: {\n",
            "  \"model\": \"gpt-4\",\n",
            "  \"input\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"You are a helpful assistant.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"What is deep learning?\"\n",
            "    }\n",
            "  ],\n",
            "  \"output\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"Deep learning is a type of machine learning based on artificial neural networks with multiple layers.\"\n",
            "  },\n",
            "  \"custom_identifier\": \"Custom workflow test_log_3\",\n",
            "  \"span_name\": \"Custom workflow test\"\n",
            "}\n",
            "\n",
            "‚úì Log created successfully\n",
            "  Log ID (unique_id): 3c8d1c065ac248d690a5cb3dfb1bab34\n",
            "‚úÖ Log created with ID: 3c8d1c065ac248d6...\n",
            "‚úÖ Created 3 logs total\n",
            "‚ÑπÔ∏è  Waiting for logs to persist in database...\n",
            "\n",
            "Waiting 15 seconds for processing...\n",
            "‚úì Wait complete\n"
          ]
        }
      ],
      "source": [
        "print_step(1, \"Create Sample Logs\")\n",
        "\n",
        "log_examples = [\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What is machine learning?\"}\n",
        "        ],\n",
        "        \"response\": \"Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience.\"\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Explain neural networks briefly.\"}\n",
        "        ],\n",
        "        \"response\": \"Neural networks are computing systems inspired by biological neural networks in animal brains.\"\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What is deep learning?\"}\n",
        "        ],\n",
        "        \"response\": \"Deep learning is a type of machine learning based on artificial neural networks with multiple layers.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for i, example in enumerate(log_examples, 1):\n",
        "    print(f\"\\nCreating log {i}/{len(log_examples)}...\")\n",
        "    log_result = create_log(\n",
        "        model=example[\"model\"],\n",
        "        input_messages=example[\"messages\"],\n",
        "        output_message={\"role\": \"assistant\", \"content\": example[\"response\"]},\n",
        "        custom_identifier=f\"{WORKFLOW_NAME}_log_{i}\",\n",
        "        span_name=WORKFLOW_NAME\n",
        "    )\n",
        "    log_id = log_result.get('unique_id') or log_result.get('id')\n",
        "    if log_id:\n",
        "        log_ids.append(log_id)\n",
        "        print_success(f\"Log created with ID: {log_id[:16]}...\")\n",
        "\n",
        "print_success(f\"Created {len(log_ids)} logs total\")\n",
        "print_info(\"Waiting for logs to persist in database...\")\n",
        "wait_for_processing(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Dataset from Logs\n",
        "\n",
        "Create a dataset using the logs we just created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 2: Create Dataset from Logs\n",
            "======================================================================\n",
            "Creating dataset...\n",
            "  URL: https://api.keywordsai.co/api/datasets\n",
            "  Name: Custom workflow test\n",
            "  Type: sampling\n",
            "  Request Body: {\n",
            "  \"name\": \"Custom workflow test\",\n",
            "  \"description\": \"Dataset created from complete self-contained notebook\",\n",
            "  \"type\": \"sampling\",\n",
            "  \"start_time\": \"2025-12-01T02:26:22.656038Z\",\n",
            "  \"end_time\": \"2025-12-03T02:26:22.656038Z\",\n",
            "  \"initial_log_filters\": {\n",
            "    \"id\": {\n",
            "      \"value\": [\n",
            "        \"07f3059ef0564f5095dc7425166cd20a\",\n",
            "        \"e8384e0bf1c847be89efed6eb0286e44\",\n",
            "        \"3c8d1c065ac248d690a5cb3dfb1bab34\"\n",
            "      ],\n",
            "      \"operator\": \"in\"\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3h/z7vpqhz947d5ckx70zcxmh080000gn/T/ipykernel_97058/3144416809.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  end_time = datetime.utcnow()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úì Dataset created successfully\n",
            "  Dataset ID: 7c07e9c8-aafc-4b77-85af-834f59f7ff9f\n",
            "  Name: Custom workflow test\n",
            "  Status: initializing\n",
            "‚úÖ Dataset created with ID: 7c07e9c8-aafc-4b77-85af-834f59f7ff9f\n",
            "‚ÑπÔ∏è  Waiting for dataset to populate...\n",
            "\n",
            "Waiting 15 seconds for processing...\n",
            "‚úì Wait complete\n"
          ]
        }
      ],
      "source": [
        "print_step(2, \"Create Dataset from Logs\")\n",
        "\n",
        "end_time = datetime.utcnow()\n",
        "start_time = end_time - timedelta(days=2)\n",
        "\n",
        "initial_filters = {\n",
        "    \"id\": {\n",
        "        \"value\": log_ids,\n",
        "        \"operator\": \"in\"\n",
        "    }\n",
        "}\n",
        "\n",
        "dataset_result = create_dataset(\n",
        "    name=WORKFLOW_NAME,\n",
        "    description=\"Dataset created from complete self-contained notebook\",\n",
        "    dataset_type=\"sampling\",\n",
        "    start_time=start_time.isoformat() + \"Z\",\n",
        "    end_time=end_time.isoformat() + \"Z\",\n",
        "    initial_log_filters=initial_filters\n",
        ")\n",
        "\n",
        "dataset_id = dataset_result.get('id')\n",
        "print_success(f\"Dataset created with ID: {dataset_id}\")\n",
        "print_info(\"Waiting for dataset to populate...\")\n",
        "wait_for_processing(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify Dataset Contains the Logs \n",
        "\n",
        "This is a critical verification step to ensure the dataset actually contains the logs we created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 3: Verify Dataset Contains the Logs\n",
            "======================================================================\n",
            "\n",
            "Listing logs for dataset 7c07e9c8-aafc-4b77-85af-834f59f7ff9f...\n",
            "  URL: https://api.keywordsai.co/api/datasets/7c07e9c8-aafc-4b77-85af-834f59f7ff9f/logs/list\n",
            "  Method: GET\n",
            "  Params: {'page': 1, 'page_size': 100}\n",
            "‚úì Retrieved 3 logs (page 1)\n",
            "  Total logs in dataset: 3\n",
            "\n",
            "  üìã First log structure:\n",
            "    Keys: ['id', 'organization_id', 'organization_key_id', 'environment', 'timestamp', 'start_time', 'prompt_id', 'prompt_name', 'trace_unique_id', 'customer_identifier', 'thread_identifier', 'custom_identifier', 'unique_organization_id', 'log_type', 'prompt_tokens', 'completion_tokens', 'total_request_tokens', 'cost', 'model', 'latency', 'tokens_per_second', 'time_to_first_token', 'routing_time', 'status_code', 'status', 'blurred', 'metadata', 'storage_object_key', 'updated_storage_object_key', 'system', 'prompt', 'completion', 'unique_id', 'dataset_id', 'updated_at', 'updated_by_email', 'input', 'output', 'annotation_status', 'annotation_completed_by', 'scores']\n",
            "    Log ID: 07f3059ef0564f5095dc7425166cd20a\n",
            "    Input preview: [{\"content\": \"You are a helpful assistant.\", \"role\": \"system\"}, {\"content\": \"What is machine learnin...\n",
            "    Output preview: {\"content\": \"Machine learning is a subset of artificial intelligence that enables systems to learn a...\n",
            "Expected logs: 3\n",
            "Dataset contains: 3 logs\n",
            "Retrieved for verification: 3 logs\n",
            "‚úÖ Dataset successfully populated with all 3 logs!\n",
            "\n",
            "üìã Sample log from dataset:\n",
            "  ID: 07f3059ef0564f5095dc7425...\n",
            "  Has input: Yes (121 chars)\n",
            "  Has output: Yes (150 chars)\n"
          ]
        }
      ],
      "source": [
        "print_step(3, \"Verify Dataset Contains the Logs\")\n",
        "\n",
        "dataset_logs = list_dataset_logs(dataset_id, page=1, page_size=100)\n",
        "dataset_log_count = len(dataset_logs.get('results', []))\n",
        "total_dataset_logs = dataset_logs.get('count', 0)\n",
        "\n",
        "print(f\"Expected logs: {len(log_ids)}\")\n",
        "print(f\"Dataset contains: {total_dataset_logs} logs\")\n",
        "print(f\"Retrieved for verification: {dataset_log_count} logs\")\n",
        "\n",
        "if dataset_log_count == 0:\n",
        "    print_error(\"Dataset is empty! Workflow cannot proceed.\")\n",
        "    raise Exception(\"Dataset is empty\")\n",
        "elif dataset_log_count < len(log_ids):\n",
        "    print_warning(f\"Expected {len(log_ids)} but found {dataset_log_count}\")\n",
        "    print_info(\"Some logs may not have been added yet, but proceeding...\")\n",
        "else:\n",
        "    print_success(f\"Dataset successfully populated with all {dataset_log_count} logs!\")\n",
        "\n",
        "if dataset_log_count > 0:\n",
        "    first_log = dataset_logs['results'][0]\n",
        "    print(f\"\\nüìã Sample log from dataset:\")\n",
        "    print(f\"  ID: {first_log.get('id', 'N/A')[:24]}...\")\n",
        "    if 'input' in first_log:\n",
        "        print(f\"  Has input: Yes ({len(str(first_log['input']))} chars)\")\n",
        "    if 'output' in first_log:\n",
        "        print(f\"  Has output: Yes ({len(str(first_log['output']))} chars)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Custom Evaluator\n",
        "\n",
        "Create an LLM-based evaluator that rates response quality on a 1-5 scale based on accuracy, relevance, and completeness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 4: Create Custom Evaluator\n",
            "======================================================================\n",
            "Creating evaluator...\n",
            "  URL: https://api.keywordsai.co/api/evaluators\n",
            "  Name: Custom workflow test\n",
            "  Slug: custom_workflow_test_eval_1764728798\n",
            "  Type: llm\n",
            "  Score Type: numerical\n",
            "  Request Body: {\n",
            "  \"name\": \"Custom workflow test\",\n",
            "  \"evaluator_slug\": \"custom_workflow_test_eval_1764728798\",\n",
            "  \"type\": \"llm\",\n",
            "  \"score_value_type\": \"numerical\",\n",
            "  \"description\": \"Evaluates response quality on a 1-5 scale\",\n",
            "  \"configurations\": {\n",
            "    \"evaluator_definition\": \"Rate the response quality based on accuracy, relevance, and completeness.\\n<llm_input>{{llm_input}}</llm_input>\\n<llm_output>{{llm_output}}</llm_output>\",\n",
            "    \"scoring_rubric\": \"1=Poor, 2=Fair, 3=Good, 4=Very Good, 5=Excellent\",\n",
            "    \"llm_engine\": \"gpt-4o-mini\",\n",
            "    \"model_options\": {\n",
            "      \"temperature\": 0.1,\n",
            "      \"max_tokens\": 200\n",
            "    },\n",
            "    \"min_score\": 1.0,\n",
            "    \"max_score\": 5.0,\n",
            "    \"passing_score\": 3.0\n",
            "  }\n",
            "}\n",
            "\n",
            "‚úì Evaluator created successfully\n",
            "  Evaluator ID: b8ad98ee-4f01-47e2-9fc8-e7cc1af93c8a\n",
            "  Evaluator Slug: custom_workflow_test_eval_1764728798\n",
            "‚úÖ Evaluator created with slug: custom_workflow_test_eval_1764728798\n"
          ]
        }
      ],
      "source": [
        "print_step(4, \"Create Custom Evaluator\")\n",
        "\n",
        "evaluator_slug = f\"custom_workflow_test_eval_{int(time.time())}\"\n",
        "\n",
        "evaluator_result = create_evaluator(\n",
        "    name=WORKFLOW_NAME,\n",
        "    evaluator_slug=evaluator_slug,\n",
        "    evaluator_type=\"llm\",\n",
        "    score_value_type=\"numerical\",\n",
        "    description=\"Evaluates response quality on a 1-5 scale\",\n",
        "    configurations={\n",
        "        \"evaluator_definition\": \"Rate the response quality based on accuracy, relevance, and completeness.\\n<llm_input>{{llm_input}}</llm_input>\\n<llm_output>{{llm_output}}</llm_output>\",\n",
        "        \"scoring_rubric\": \"1=Poor, 2=Fair, 3=Good, 4=Very Good, 5=Excellent\",\n",
        "        \"llm_engine\": \"gpt-4o-mini\",\n",
        "        \"model_options\": {\n",
        "            \"temperature\": 0.1,\n",
        "            \"max_tokens\": 200\n",
        "        },\n",
        "        \"min_score\": 1.0,\n",
        "        \"max_score\": 5.0,\n",
        "        \"passing_score\": 3.0\n",
        "    }\n",
        ")\n",
        "\n",
        "print_success(f\"Evaluator created with slug: {evaluator_slug}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Experiment with Dataset and Evaluator\n",
        "\n",
        "Create a custom workflow experiment that will create placeholder traces for each dataset entry.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 5: Create Experiment with Dataset and Evaluator\n",
            "======================================================================\n",
            "Creating custom workflow experiment...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/\n",
            "  Name: Custom workflow test\n",
            "  Dataset: 7c07e9c8-aafc-4b77-85af-834f59f7ff9f\n",
            "  Evaluators: custom_workflow_test_eval_1764728798\n",
            "  Request Body: {\n",
            "  \"name\": \"Custom workflow test\",\n",
            "  \"description\": \"Testing complete self-contained workflow\",\n",
            "  \"dataset_id\": \"7c07e9c8-aafc-4b77-85af-834f59f7ff9f\",\n",
            "  \"workflows\": [\n",
            "    {\n",
            "      \"type\": \"custom\",\n",
            "      \"config\": {\n",
            "        \"name\": \"Custom workflow test\",\n",
            "        \"description\": \"Custom workflow from complete notebook\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"evaluator_slugs\": [\n",
            "    \"custom_workflow_test_eval_1764728798\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "‚úì Experiment created with ID: 0afd625010e34900bb644efa1649ee3a\n",
            "  Status: pending\n",
            "  Placeholder traces are being created asynchronously...\n",
            "‚úÖ Experiment created with ID: 0afd625010e34900bb644efa1649ee3a\n",
            "‚ÑπÔ∏è  Placeholder traces being created asynchronously...\n"
          ]
        }
      ],
      "source": [
        "print_step(5, \"Create Experiment with Dataset and Evaluator\")\n",
        "\n",
        "experiment_data = create_experiment(\n",
        "    name=WORKFLOW_NAME,\n",
        "    description=\"Testing complete self-contained workflow\",\n",
        "    dataset_id=dataset_id,\n",
        "    workflows=[{\n",
        "        \"type\": \"custom\",\n",
        "        \"config\": {\n",
        "            \"name\": WORKFLOW_NAME,\n",
        "            \"description\": \"Custom workflow from complete notebook\"\n",
        "        }\n",
        "    }],\n",
        "    evaluator_slugs=[evaluator_slug]\n",
        ")\n",
        "\n",
        "experiment_id = experiment_data.get('id')\n",
        "print_success(f\"Experiment created with ID: {experiment_id}\")\n",
        "print_info(\"Placeholder traces being created asynchronously...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Wait for Traces and List Placeholder Traces\n",
        "\n",
        "Wait for async trace creation and retrieve the placeholder traces with retry logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 6: Wait for Traces and List Placeholder Traces\n",
            "======================================================================\n",
            "‚ÑπÔ∏è  Waiting for placeholder traces (with retry)...\n",
            "  Attempt 1/6...\n",
            "\n",
            "Waiting 10 seconds for processing...\n",
            "‚úì Wait complete\n",
            "\n",
            "Listing experiment logs for 0afd625010e34900bb644efa1649ee3a...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/list/\n",
            "  Params: {'page': 1, 'page_size': 10}\n",
            "  Method: GET\n",
            "‚úì Found 3 logs (page 1)\n",
            "  Total count: 3\n",
            "  Status breakdown: {'pending': 3}\n",
            "‚úÖ Found 3 traces on attempt 1\n",
            "\n",
            "Listing experiment logs for 0afd625010e34900bb644efa1649ee3a...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/list/\n",
            "  Params: {'page': 1, 'page_size': 10}\n",
            "  Method: GET\n",
            "‚úì Found 3 logs (page 1)\n",
            "  Total count: 3\n",
            "  Status breakdown: {'pending': 3}\n",
            "\n",
            "Found 3 traces\n",
            "‚úÖ Successfully retrieved 3 traces\n",
            "\n",
            "Status breakdown:\n",
            "  pending: 3\n"
          ]
        }
      ],
      "source": [
        "print_step(6, \"Wait for Traces and List Placeholder Traces\")\n",
        "\n",
        "print_info(\"Waiting for placeholder traces (with retry)...\")\n",
        "\n",
        "trace_count = 0\n",
        "max_retries = 6\n",
        "retry_wait = 10\n",
        "\n",
        "for attempt in range(1, max_retries + 1):\n",
        "    print(f\"  Attempt {attempt}/{max_retries}...\")\n",
        "    wait_for_processing(retry_wait)\n",
        "    \n",
        "    traces_response = list_experiment_logs(experiment_id, filters=None, page_size=10)\n",
        "    trace_count = len(traces_response.get('results', []))\n",
        "    \n",
        "    if trace_count > 0:\n",
        "        print_success(f\"Found {trace_count} traces on attempt {attempt}\")\n",
        "        break\n",
        "    else:\n",
        "        if attempt < max_retries:\n",
        "            print_info(f\"No traces yet, waiting {retry_wait} more seconds...\")\n",
        "\n",
        "traces = list_experiment_logs(experiment_id, filters=None, page_size=10)\n",
        "trace_count = len(traces.get('results', []))\n",
        "\n",
        "print(f\"\\nFound {trace_count} traces\")\n",
        "\n",
        "if trace_count == 0:\n",
        "    print_error(\"No traces found after multiple retries!\")\n",
        "    raise Exception(\"No traces found\")\n",
        "\n",
        "print_success(f\"Successfully retrieved {trace_count} traces\")\n",
        "\n",
        "status_breakdown = {}\n",
        "for trace in traces.get('results', []):\n",
        "    status = trace.get('status', 'unknown')\n",
        "    status_breakdown[status] = status_breakdown.get(status, 0) + 1\n",
        "\n",
        "print(f\"\\nStatus breakdown:\")\n",
        "for status, count in status_breakdown.items():\n",
        "    print(f\"  {status}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Process Traces with Custom Workflow\n",
        "\n",
        "Process each trace with our custom logic and submit the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 7: Process Traces with Custom Workflow\n",
            "======================================================================\n",
            "3\n",
            "\n",
            "Processing trace 1/3 (485238aa52964d4f84ad70146e0f6d30)...\n",
            "    Submitting results to: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/485238aa52964d4f84ad70146e0f6d30/\n",
            "    Method: PATCH\n",
            "    Payload keys: ['input', 'output', 'name', 'metadata']\n",
            "    Input type: str\n",
            "    Output type: dict\n",
            "    Response status: 200\n",
            "    Trace status: success\n",
            "‚úÖ Submitted results for trace 485238aa52964d4f...\n",
            "\n",
            "Processing trace 2/3 (4dd1436e510a47d6b5524f4e26ac190b)...\n",
            "    Submitting results to: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/4dd1436e510a47d6b5524f4e26ac190b/\n",
            "    Method: PATCH\n",
            "    Payload keys: ['input', 'output', 'name', 'metadata']\n",
            "    Input type: str\n",
            "    Output type: dict\n",
            "    Response status: 200\n",
            "    Trace status: success\n",
            "‚úÖ Submitted results for trace 4dd1436e510a47d6...\n",
            "\n",
            "Processing trace 3/3 (17221c06b98d42aea3089948bb10bafb)...\n",
            "    Submitting results to: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/17221c06b98d42aea3089948bb10bafb/\n",
            "    Method: PATCH\n",
            "    Payload keys: ['input', 'output', 'name', 'metadata']\n",
            "    Input type: str\n",
            "    Output type: dict\n",
            "    Response status: 200\n",
            "    Trace status: success\n",
            "‚úÖ Submitted results for trace 17221c06b98d42ae...\n",
            "‚úÖ Processed and submitted 3 traces\n",
            "‚ÑπÔ∏è  Waiting for evaluators to execute...\n",
            "\n",
            "Waiting 15 seconds for processing...\n",
            "‚úì Wait complete\n"
          ]
        }
      ],
      "source": [
        "print_step(7, \"Process Traces with Custom Workflow\")\n",
        "\n",
        "processed_count = 0\n",
        "max_to_process = min(trace_count, 3)\n",
        "print(max_to_process)\n",
        "for i, trace in enumerate(traces['results'][:max_to_process], 1):\n",
        "    trace_id = trace.get('id')\n",
        "    trace_ids.append(trace_id)\n",
        "    \n",
        "    print(f\"\\nProcessing trace {i}/{max_to_process} ({trace_id})...\")\n",
        "    \n",
        "    input_data = trace.get('input')\n",
        "    \n",
        "    result = process_with_custom_logic(input_data)\n",
        "    \n",
        "    updated_trace = submit_workflow_results(\n",
        "        exp_id=experiment_id,\n",
        "        trace_id=trace_id,\n",
        "        input_data=input_data,\n",
        "        output_data=result['output'],\n",
        "        name=WORKFLOW_NAME,\n",
        "        metadata=result.get('metadata')\n",
        "    )\n",
        "    \n",
        "    processed_count += 1\n",
        "    print_success(f\"Submitted results for trace {trace_id[:16]}...\")\n",
        "\n",
        "print_success(f\"Processed and submitted {processed_count} traces\")\n",
        "print_info(\"Waiting for evaluators to execute...\")\n",
        "wait_for_processing(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Verify Experiment Results \n",
        "\n",
        "Get comprehensive results including status breakdown and evaluator execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 8: Verify Experiment Results\n",
            "======================================================================\n",
            "\n",
            "Getting experiment summary for 0afd625010e34900bb644efa1649ee3a...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/summary/\n",
            "  Method: GET\n",
            "‚úì Summary retrieved:\n",
            "  Total traces: 3\n",
            "  Total cost: $0.0000\n",
            "  Total tokens: 0\n",
            "  Avg latency: 12.33s\n",
            "\n",
            "üìä Experiment Summary:\n",
            "  Total traces: 3\n",
            "  Total cost: $0.0000\n",
            "  Total tokens: 0\n",
            "  Avg latency: 12.33s\n",
            "\n",
            "Listing experiment logs for 0afd625010e34900bb644efa1649ee3a...\n",
            "  URL: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/list/\n",
            "  Params: {'page': 1, 'page_size': 100}\n",
            "  Method: GET\n",
            "‚úì Found 3 logs (page 1)\n",
            "  Total count: 3\n",
            "  Status breakdown: {'success': 3}\n",
            "\n",
            "üìà Final Status Breakdown:\n",
            "  success: 3 (100.0%)\n",
            "\n",
            "üîç Checking Evaluator Execution:\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/485238aa52964d4f84ad70146e0f6d30/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "  ‚ö†Ô∏è  Trace 485238aa52964d4f... has no evaluator results yet\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/4dd1436e510a47d6b5524f4e26ac190b/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "  ‚ö†Ô∏è  Trace 4dd1436e510a47d6... has no evaluator results yet\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/17221c06b98d42aea3089948bb10bafb/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "  ‚ö†Ô∏è  Trace 17221c06b98d42ae... has no evaluator results yet\n",
            "‚ö†Ô∏è  No evaluator results found (may still be processing)\n"
          ]
        }
      ],
      "source": [
        "print_step(8, \"Verify Experiment Results\")\n",
        "\n",
        "try:\n",
        "    final_summary = get_experiment_summary(experiment_id)\n",
        "    print(f\"\\nüìä Experiment Summary:\")\n",
        "    print(f\"  Total traces: {final_summary.get('total_count', 0)}\")\n",
        "    print(f\"  Total cost: ${final_summary.get('total_cost', 0):.4f}\")\n",
        "    print(f\"  Total tokens: {final_summary.get('total_tokens', 0)}\")\n",
        "    print(f\"  Avg latency: {final_summary.get('avg_latency', 0):.2f}s\")\n",
        "except Exception as e:\n",
        "    print_warning(f\"Could not get summary: {e}\")\n",
        "    final_summary = {}\n",
        "\n",
        "all_traces = list_experiment_logs(experiment_id, filters=None)\n",
        "final_status_breakdown = {}\n",
        "for trace in all_traces.get('results', []):\n",
        "    status = trace.get('status', 'unknown')\n",
        "    final_status_breakdown[status] = final_status_breakdown.get(status, 0) + 1\n",
        "\n",
        "print(f\"\\nüìà Final Status Breakdown:\")\n",
        "for status, count in final_status_breakdown.items():\n",
        "    total = all_traces.get('count', 1)\n",
        "    percentage = (count / total * 100) if total > 0 else 0\n",
        "    print(f\"  {status}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nüîç Checking Evaluator Execution:\")\n",
        "traces_with_evaluators = 0\n",
        "\n",
        "for trace_id in trace_ids[:3]:\n",
        "    trace_detail = get_trace_details(experiment_id, trace_id, include_full_span_tree=True)\n",
        "    span_tree = trace_detail.get('span_tree', [])\n",
        "    \n",
        "    evaluator_spans = [\n",
        "        span for span in span_tree\n",
        "        if span.get('span_type') == 'SCORE' or 'evaluator' in span.get('span_name', '').lower()\n",
        "    ]\n",
        "    \n",
        "    if evaluator_spans:\n",
        "        traces_with_evaluators += 1\n",
        "        print(f\"  ‚úì Trace {trace_id[:16]}... has {len(evaluator_spans)} evaluator span(s)\")\n",
        "        for eval_span in evaluator_spans:\n",
        "            span_name = eval_span.get('span_name', 'unknown')\n",
        "            score = eval_span.get('score', 'N/A')\n",
        "            print(f\"    - {span_name}: score = {score}\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è  Trace {trace_id[:16]}... has no evaluator results yet\")\n",
        "\n",
        "if traces_with_evaluators > 0:\n",
        "    print_success(f\"Evaluators executed on {traces_with_evaluators}/{len(trace_ids[:3])} sampled traces\")\n",
        "else:\n",
        "    print_warning(\"No evaluator results found (may still be processing)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Debug - View Full Span Tree Structure\n",
        "\n",
        "Let's inspect the actual span tree structure to see where the evaluator results are.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 9: Debug - View Full Span Tree Structure\n",
            "======================================================================\n",
            "‚ÑπÔ∏è  Waiting 20 seconds to ensure evaluators have fully completed...\n",
            "\n",
            "Waiting 20 seconds for processing...\n",
            "‚úì Wait complete\n",
            "\n",
            "üîç Inspecting trace: 485238aa52964d4f84ad70146e0f6d30\n",
            "  Getting trace details...\n",
            "    URL: https://api.keywordsai.co/api/v2/experiments/0afd625010e34900bb644efa1649ee3a/logs/485238aa52964d4f84ad70146e0f6d30/\n",
            "    Method: GET\n",
            "    Params: {'detail': 1}\n",
            "\n",
            "üìã Trace-level keys: ['id', 'trace_unique_id', 'root_span_unique_id', 'unique_organization_id', 'environment', 'customer_identifier', 'start_time', 'end_time', 'duration', 'span_count', 'llm_call_count', 'total_cost', 'total_prompt_tokens', 'total_completion_tokens', 'total_tokens', 'error_count', 'name', 'input', 'output', 'storage_object_key', 'comparison_key', 'status', 'updated_storage_object_key', 'span_tree']\n",
            "\n",
            "üå≤ Span Tree: 1 total spans\n",
            "\n",
            "  [1] Span Details:\n",
            "      span_name: experiment_trace\n",
            "      span_type: N/A\n",
            "      log_type: workflow\n",
            "      status: success\n",
            "      Available keys: ['id', 'organization_id', 'organization_key_id', 'environment', 'timestamp', 'start_time', 'prompt_id', 'prompt_name', 'trace_unique_id', 'customer_identifier', 'thread_identifier', 'custom_identifier', 'unique_organization_id', 'log_type', 'prompt_tokens', 'completion_tokens', 'total_request_tokens', 'cost', 'model', 'latency', 'tokens_per_second', 'time_to_first_token', 'routing_time', 'status_code', 'status', 'blurred', 'metadata', 'storage_object_key', 'updated_storage_object_key', 'system', 'prompt', 'completion', 'unique_id', 'dataset_id', 'span_name', 'updated_at', 'updated_by_email', 'input', 'output', 'end_time', 'children']\n",
            "      output: {\"custom_field\": \"your_custom_value\", \"input_preview\": \"[{'content': 'You are a helpful assistant.', 'role': 'system'}, {'content': 'Explain neural networks\", \"message\": \"Successfully processed input ...\n",
            "      children: 1 child span(s)\n",
            "        [1] evaluator.custom_workflow_test_eval_1764728798 (type: N/A)\n"
          ]
        }
      ],
      "source": [
        "print_step(9, \"Debug - View Full Span Tree Structure\")\n",
        "\n",
        "# Wait a bit more to ensure evaluators have completed\n",
        "print_info(\"Waiting 20 seconds to ensure evaluators have fully completed...\")\n",
        "wait_for_processing(20)\n",
        "\n",
        "# Get first trace with full details\n",
        "if trace_ids:\n",
        "    first_trace_id = trace_ids[0]\n",
        "    print(f\"\\nüîç Inspecting trace: {first_trace_id}\")\n",
        "    \n",
        "    trace_detail = get_trace_details(experiment_id, first_trace_id, include_full_span_tree=True)\n",
        "    \n",
        "    print(f\"\\nüìã Trace-level keys: {list(trace_detail.keys())}\")\n",
        "    \n",
        "    span_tree = trace_detail.get('span_tree', [])\n",
        "    print(f\"\\nüå≤ Span Tree: {len(span_tree)} total spans\")\n",
        "    \n",
        "    if not span_tree:\n",
        "        print_error(\"Span tree is empty!\")\n",
        "    else:\n",
        "        for i, span in enumerate(span_tree, 1):\n",
        "            print(f\"\\n  [{i}] Span Details:\")\n",
        "            print(f\"      span_name: {span.get('span_name', 'N/A')}\")\n",
        "            print(f\"      span_type: {span.get('span_type', 'N/A')}\")\n",
        "            print(f\"      log_type: {span.get('log_type', 'N/A')}\")\n",
        "            print(f\"      status: {span.get('status', 'N/A')}\")\n",
        "            \n",
        "            # Show all keys to see what's available\n",
        "            print(f\"      Available keys: {list(span.keys())}\")\n",
        "            \n",
        "            # Check for score-related fields\n",
        "            if 'score' in span:\n",
        "                print(f\"      ‚≠ê score: {span['score']}\")\n",
        "            if 'evaluation_result' in span:\n",
        "                print(f\"      evaluation_result: {span['evaluation_result']}\")\n",
        "            if 'evaluator_slug' in span:\n",
        "                print(f\"      evaluator_slug: {span['evaluator_slug']}\")\n",
        "            \n",
        "            # Show output if it's small enough\n",
        "            output = span.get('output', '')\n",
        "            if output:\n",
        "                output_str = str(output)\n",
        "                if len(output_str) > 200:\n",
        "                    print(f\"      output: {output_str[:200]}...\")\n",
        "                else:\n",
        "                    print(f\"      output: {output_str}\")\n",
        "            \n",
        "            # Check if this span has children\n",
        "            if 'children' in span:\n",
        "                children = span.get('children', [])\n",
        "                print(f\"      children: {len(children)} child span(s)\")\n",
        "                if children:\n",
        "                    for j, child in enumerate(children, 1):\n",
        "                        print(f\"        [{j}] {child.get('span_name', 'N/A')} (type: {child.get('span_type', 'N/A')})\")\n",
        "else:\n",
        "    print_warning(\"No trace IDs available to inspect\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
